{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心概念\n",
    "\n",
    "\n",
    "## Tensor 对象 (张量)\n",
    "\n",
    "- 可以是标量、向量 、三维矩阵、N维矩阵\n",
    "- 可以使用 `tf.constant` \\ `tf.Variable` 创建\n",
    "- 每个 Tensor 对象具有\n",
    "    - Type: string / float32 / float16 / int8 等数据类型\n",
    "    - Shape: 数据维度\n",
    "    - Rank: 维数， 标量 为 0阶、向量 1 阶、三维矩阵 2阶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 图\n",
    "\n",
    "## 无环图 (Directed Acyclic Graph, DAG)\n",
    "\n",
    "优点\n",
    "\n",
    "- 利用GPU\n",
    "- 分布运算\n",
    "- 避免不必要预算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    }
   ],
   "source": [
    "#  在TensorFlow2 中创建图\n",
    "\n",
    "def compute(a, b, c):\n",
    "    d = a * b + c\n",
    "    e = a * b * c\n",
    "    return d, e\n",
    "\n",
    "\n",
    "print(compute(1,2,3))\n",
    "#  正常情况下需要计算两次 a * b，比较浪费\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=5>, <tf.Tensor: shape=(), dtype=int32, numpy=6>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 使用装饰器\n",
    "\n",
    "@tf.function\n",
    "def compute(a, b, c):\n",
    "    d = a * b + c\n",
    "    e = a * b * c\n",
    "    return d, e\n",
    "\n",
    "print(compute(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGraph \n",
    "\n",
    "- 可以转换大多python，例如 for，while， if\n",
    "- 比即时执行更快\n",
    "- 向其他设备导出模型\n",
    "- 性能最优\n",
    "- 自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 自动微分案例\n",
    "\n",
    "A, B = tf.constant(3.0), tf.constant(6.0)\n",
    "X = tf.Variable(20.0)\n",
    "# 定义损失函数\n",
    "loss = tf.math.abs(A*X - B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(X) = AX+B \\\\\n",
    "\n",
    "f'(X) =  A\n",
    "$$\n",
    "\n",
    "在这里导数固定为 A，即 3，使用  `tape.gradient` 调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientTape 梯度带\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        lossValue = tf.math.abs(A*X - B)\n",
    "    dX = tape.gradient(lossValue, X)\n",
    "    print('X = {:2f}, dX = {:.2f}'.format(X.numpy(), dX))\n",
    "    # X  重新赋值\n",
    "    X.assign(X - dX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = 20.000000, dX = 3.00\n",
      "X = 17.000000, dX = 3.00\n",
      "X = 14.000000, dX = 3.00\n",
      "X = 11.000000, dX = 3.00\n",
      "X = 8.000000, dX = 3.00\n",
      "X = 5.000000, dX = 3.00\n",
      "X = 2.000000, dX = 0.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    train_step()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83e29bc4780094a1020ea993be7b4ac962c5dfd5f12c392e72ec0e6eface9c7b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('learn-tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
